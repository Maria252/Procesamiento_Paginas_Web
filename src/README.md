# ğŸ¢ Workshop: ExtracciÃ³n Automatizada de InformaciÃ³n de Empresas

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/tu-usuario/repo-name/HEAD?labpath=notebooks%2Fcaptacion_info_empresas.ipynb)

## ğŸ“‹ DescripciÃ³n

Este repositorio contiene un taller interactivo para construir un sistema automatizado de extracciÃ³n de informaciÃ³n empresarial que combina web scraping avanzado con anÃ¡lisis de IA.

### ğŸ¯ Objetivos del Taller

- Aprender web scraping moderno con **Playwright**
- Integrar **Google Gemini** para anÃ¡lisis de contenido con IA
- Implementar **procesamiento secuencial** para mayor estabilidad
- Gestionar errores y optimizar performance
- Exportar datos estructurados para anÃ¡lisis

## ğŸš€ Inicio RÃ¡pido

### OpciÃ³n 1: MyBinder (Recomendado para el taller)

1. Haz clic en el botÃ³n **"launch binder"** arriba
2. Espera a que se construya el entorno (puede tomar 2-3 minutos)
3. Abre el notebook `notebooks/captacion_info_empresas.ipynb`
4. Sigue las instrucciones paso a paso

### OpciÃ³n 2: InstalaciÃ³n Local

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/repo-name.git
cd repo-name

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r binder/requirements.txt

# Instalar navegadores de Playwright
python -m playwright install chromium

# Ejecutar Jupyter
jupyter lab notebooks/captacion_info_empresas.ipynb
```

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ binder/
â”‚   â”œâ”€â”€ requirements.txt    # Dependencias Python
â”‚   â”œâ”€â”€ runtime.txt        # VersiÃ³n de Python
â”‚   â””â”€â”€ postBuild          # Script post-instalaciÃ³n
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ captacion_info_empresas.ipynb  # Notebook principal del taller
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ companies_demo.csv             # Datos de ejemplo
â”‚   â”œâ”€â”€ htmls/                         # HTMLs descargados
â”‚   â””â”€â”€ processed/                     # Resultados procesados
â”œâ”€â”€ README.md
â””â”€â”€ 0_html_processing.py               # CÃ³digo original de referencia
```

## ğŸ› ï¸ Requisitos

### Dependencias Principales
- **Python 3.10+**
- **Google AI API Key** (obtener en https://makersuite.google.com/app/apikey)
- **Playwright** para web scraping
- **Pandas** para manipulaciÃ³n de datos
- **BeautifulSoup** para parsing HTML

### API Key de Google AI
```python
# Durante el taller, se te pedirÃ¡ ingresar tu API key
# Alternativamente, puedes configurar la variable de entorno:
export GOOGLE_AI_API_KEY="tu-api-key-aqui"
```

## ğŸ“Š Datos de Entrada

El sistema procesa un archivo Excel con las siguientes columnas:
- `Company Name`: Nombre de la empresa
- `Website`: URL del sitio web

### Ejemplo de datos:
```
Company Name         | Website
ProColombia         | https://procolombia.co
Bancolombia         | https://www.bancolombia.com
Avianca             | https://www.avianca.com
```

## ğŸ“ˆ Datos de Salida

El sistema extrae la siguiente informaciÃ³n de cada empresa:
- **hq_city**: Ciudad de la sede
- **hq_state**: Estado/provincia de la sede
- **company_description**: DescripciÃ³n breve de la empresa
- **sector**: Sector industrial
- **presence_in_latam**: Presencia en LatinoamÃ©rica
- **sustainability_reports**: Reportes de sostenibilidad
- **contact_phone**: TelÃ©fonos de contacto

## ğŸ­ CaracterÃ­sticas TÃ©cnicas

### Web Scraping Avanzado
- **Renderizado JavaScript** con Playwright
- **Manejo de contenido dinÃ¡mico** y lazy loading
- **ExtracciÃ³n inteligente** de enlaces relevantes
- **GestiÃ³n de errores** y reintentos automÃ¡ticos

### AnÃ¡lisis con IA
- **Prompts optimizados** para extracciÃ³n de datos empresariales con Google Gemini
- **CachÃ© inteligente** para evitar llamadas repetidas a la API
- **NormalizaciÃ³n automÃ¡tica** de respuestas
- **Rate limiting** para cumplir con lÃ­mites de API

### OptimizaciÃ³n de Performance
- **Procesamiento secuencial** para mayor estabilidad
- **Sistema de checkpoints** para recuperaciÃ³n de errores
- **ValidaciÃ³n de URLs** antes del procesamiento
- **GestiÃ³n de sitios bloqueados**

## ğŸ“ Flujo de Trabajo

1. **ConfiguraciÃ³n**: InstalaciÃ³n de dependencias y configuraciÃ³n de API
2. **Carga de datos**: Lectura del archivo Excel con empresas
3. **ValidaciÃ³n**: VerificaciÃ³n de accesibilidad de sitios web
4. **Scraping**: Descarga de HTML con renderizado JavaScript
5. **AnÃ¡lisis**: ExtracciÃ³n de informaciÃ³n con Google Gemini
6. **ExportaciÃ³n**: Guardado de resultados en CSV
7. **VisualizaciÃ³n**: AnÃ¡lisis y grÃ¡ficos de los datos obtenidos

## âš¡ Performance y Escalabilidad

### Configuraciones Recomendadas
- **Procesamiento**: Secuencial (una empresa a la vez)
- **Timeout de URLs**: 15 segundos
- **Rate limit Gemini**: 2 segundos entre llamadas
- **Secciones por empresa**: MÃ¡ximo 3 secciones adicionales

### Optimizaciones Implementadas
- CachÃ© de respuestas Gemini
- ReutilizaciÃ³n de HTMLs descargados
- ValidaciÃ³n previa de URLs
- Manejo inteligente de errores

## ğŸ”§ PersonalizaciÃ³n

### Modificar Keywords de BÃºsqueda
```python
KEYWORDS = [
    'contact', 'about', 'team', 'services',
    'contacto', 'acerca', 'equipo', 'servicios'
    # Agregar mÃ¡s keywords segÃºn necesidades
]
```

### Ajustar Prompt de Gemini
```python
def build_prompt(text):
    return f"""
    Personaliza aquÃ­ el prompt segÃºn tus necesidades especÃ­ficas...
    {text}
    """
```

## ğŸ› SoluciÃ³n de Problemas

### Errores Comunes
1. **API Key invÃ¡lida**: Verificar configuraciÃ³n de Google AI
2. **Timeout de navegador**: Aumentar timeout en configuraciÃ³n
3. **Sitios bloqueados**: Revisar user-agent y headers
4. **Memoria insuficiente**: Reducir nÃºmero de secciones por empresa

### Logs y Debugging
Los logs se muestran en tiempo real durante la ejecuciÃ³n e incluyen:
- Estado de descarga de cada empresa
- Errores de conexiÃ³n y timeout
- EstadÃ­sticas de cachÃ© y performance
- Resultados de extracciÃ³n por empresa

## ğŸ“š Recursos Adicionales

- [Google AI Studio](https://makersuite.google.com/)
- [Gemini API Documentation](https://ai.google.dev/docs)
- [Playwright Python](https://playwright.dev/python/)
- [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [MyBinder Documentation](https://mybinder.readthedocs.io/)

## ğŸ¤ Contribuir

Â¿Mejoras o sugerencias? Â¡Contribuciones bienvenidas!

1. Fork el repositorio
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo LICENSE para detalles.

## ğŸ‘¨â€ğŸ’» Autor

Desarrollado para el Workshop de IA Empresarial - ProColombia 2025

---

**ğŸ‰ Â¡Disfruta aprendiendo sobre extracciÃ³n automatizada de datos empresariales!**
